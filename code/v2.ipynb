{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7303d680",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "base = Path.cwd()\n",
    "candidate = base / \"outputs\" / \"trustreg_results.csv\"\n",
    "if not candidate.exists():\n",
    "    candidate = base.parent / \"outputs\" / \"trustreg_results.csv\"\n",
    "\n",
    "df = pd.read_csv(candidate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a99b1ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def domain_risk(text):\n",
    "    legal = [\"court\",\"law\",\"violation\",\"article\",\"judgment\",\"legal\",\"rights\"]\n",
    "    medical = [\"treatment\",\"diagnosis\",\"dose\",\"disease\",\"symptom\"]\n",
    "    finance = [\"investment\",\"stock\",\"loan\",\"interest\",\"profit\"]\n",
    "\n",
    "    t = text.lower()\n",
    "\n",
    "    if any(w in t for w in legal): return 1.0\n",
    "    if any(w in t for w in medical): return 0.9\n",
    "    if any(w in t for w in finance): return 0.7\n",
    "    return 0.3\n",
    "\n",
    "\n",
    "def actionability(text):\n",
    "    actions = [\"should\",\"must\",\"recommend\",\"advise\",\"therefore\",\"you can\"]\n",
    "    return 1.0 if any(w in text.lower() for w in actions) else 0.3\n",
    "\n",
    "\n",
    "def authority_claim(text):\n",
    "    claims = [\"according to the court\",\"it is established\",\"the law states\",\"precedent\"]\n",
    "    return 1.0 if any(w in text.lower() for w in claims) else 0.4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3660023c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_harm(predicted, true):\n",
    "    if predicted==1 and true==0: return 5   # harmful false approval\n",
    "    if predicted==0 and true==1: return 1   # harmful false block\n",
    "    return 0\n",
    "\n",
    "def decision_utility(predicted, true):\n",
    "    return 1 if predicted==1 and true==1 else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35b3520d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Harm\"] = df.apply(lambda r: decision_harm(1, r[\"binary_violation\"]), axis=1)\n",
    "df[\"Utility\"] = df.apply(lambda r: decision_utility(1, r[\"binary_violation\"]), axis=1)\n",
    "\n",
    "lambda_val = 0.5   # tradeoff weight\n",
    "\n",
    "df[\"GovTarget\"] = df[\"Harm\"] - lambda_val * df[\"Utility\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b3e565f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "df[\"DomainRisk\"] = df[\"llm_answer\"].apply(domain_risk)\n",
    "df[\"ActionRisk\"] = df[\"llm_answer\"].apply(actionability)\n",
    "df[\"AuthorityRisk\"] = df[\"llm_answer\"].apply(authority_claim)\n",
    "X = df[[\n",
    "    \"FactRisk\",\"InterpretationRisk\",\"RetrievalMismatch\",\"ConfidenceGap\",\n",
    "    \"DomainRisk\",\"ActionRisk\",\"AuthorityRisk\"\n",
    "]]\n",
    "\n",
    "y = df[\"GovTarget\"]\n",
    "\n",
    "policy = LinearRegression()\n",
    "policy.fit(X,y)\n",
    "\n",
    "df[\"GovScore_v2\"] = policy.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14fd5b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trustreg_v2(score, threshold=0.0):\n",
    "    return \"BLOCK\" if score>threshold else \"APPROVE\"\n",
    "\n",
    "df[\"TrustReg_v2\"] = df[\"GovScore_v2\"].apply(trustreg_v2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9038eb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harm: 2948\n",
      "Utility: 565\n"
     ]
    }
   ],
   "source": [
    "df[\"TrustReg_v2_pred\"] = df[\"TrustReg_v2\"].apply(lambda d: 1 if d==\"APPROVE\" else 0)\n",
    "\n",
    "df[\"TrustReg_v2_harm\"] = df.apply(\n",
    "    lambda r: decision_harm(r[\"TrustReg_v2_pred\"], r[\"binary_violation\"]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df[\"TrustReg_v2_utility\"] = df.apply(\n",
    "    lambda r: decision_utility(r[\"TrustReg_v2_pred\"], r[\"binary_violation\"]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(\"Harm:\", df[\"TrustReg_v2_harm\"].sum())\n",
    "print(\"Utility:\", df[\"TrustReg_v2_utility\"].sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43417167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Harm: 881\n",
      "TEST Utility: 166\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=42)\n",
    "\n",
    "policy = LinearRegression()\n",
    "policy.fit(X_train,y_train)\n",
    "\n",
    "df_test = df.iloc[X_test.index].copy()\n",
    "\n",
    "df_test[\"GovScore_v2\"] = policy.predict(X_test)\n",
    "df_test[\"TrustReg_v2\"] = df_test[\"GovScore_v2\"].apply(trustreg_v2)\n",
    "\n",
    "df_test[\"TrustReg_v2_pred\"] = df_test[\"TrustReg_v2\"].apply(lambda d: 1 if d==\"APPROVE\" else 0)\n",
    "\n",
    "df_test[\"TrustReg_v2_harm\"] = df_test.apply(\n",
    "    lambda r: decision_harm(r[\"TrustReg_v2_pred\"], r[\"binary_violation\"]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df_test[\"TrustReg_v2_utility\"] = df_test.apply(\n",
    "    lambda r: decision_utility(r[\"TrustReg_v2_pred\"], r[\"binary_violation\"]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(\"TEST Harm:\", df_test[\"TrustReg_v2_harm\"].sum())\n",
    "print(\"TEST Utility:\", df_test[\"TrustReg_v2_utility\"].sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9509f595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3600.000000\n",
       "mean        0.068333\n",
       "std         1.674398\n",
       "min        -0.500000\n",
       "25%        -0.500000\n",
       "50%        -0.500000\n",
       "75%        -0.500000\n",
       "max         5.000000\n",
       "Name: GovTarget, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"GovTarget\"].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97524ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../outputs/trustreg_v2_results.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
