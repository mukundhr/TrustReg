{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1613aff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST TrustReg v3 Harm: 740\n",
      "TEST TrustReg v3 Utility: 427\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Load Data\n",
    "# --------------------------------------------------\n",
    "\n",
    "base = Path.cwd()\n",
    "candidate = base / \"outputs\" / \"trustreg_v2_results.csv\"\n",
    "if not candidate.exists():\n",
    "    candidate = base.parent / \"outputs\" / \"trustreg_v2_results.csv\"\n",
    "\n",
    "df = pd.read_csv(candidate)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Harm & Utility Definitions\n",
    "# --------------------------------------------------\n",
    "\n",
    "def decision_harm(predicted, true):\n",
    "    if predicted==1 and true==0: return 5\n",
    "    if predicted==0 and true==1: return 1\n",
    "    return 0\n",
    "\n",
    "def decision_utility(predicted, true):\n",
    "    return 1 if predicted==1 and true==1 else 0\n",
    "\n",
    "df[\"Harm\"] = df.apply(lambda r: decision_harm(1, r[\"binary_violation\"]), axis=1)\n",
    "df[\"Utility\"] = df.apply(lambda r: decision_utility(1, r[\"binary_violation\"]), axis=1)\n",
    "\n",
    "lambda_val = 0.5\n",
    "df[\"GovTarget\"] = df[\"Harm\"] - lambda_val * df[\"Utility\"]\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Governance Feature Functions\n",
    "# --------------------------------------------------\n",
    "\n",
    "def domain_risk(text):\n",
    "    legal = [\"court\",\"law\",\"violation\",\"article\",\"judgment\",\"legal\",\"rights\"]\n",
    "    medical = [\"treatment\",\"diagnosis\",\"dose\",\"disease\",\"symptom\"]\n",
    "    finance = [\"investment\",\"stock\",\"loan\",\"interest\",\"profit\"]\n",
    "\n",
    "    t = text.lower()\n",
    "    if any(w in t for w in legal): return 1.0\n",
    "    if any(w in t for w in medical): return 0.9\n",
    "    if any(w in t for w in finance): return 0.7\n",
    "    return 0.3\n",
    "\n",
    "def actionability(text):\n",
    "    actions = [\"should\",\"must\",\"recommend\",\"advise\",\"therefore\",\"you can\"]\n",
    "    return 1.0 if any(w in text.lower() for w in actions) else 0.3\n",
    "\n",
    "def authority_claim(text):\n",
    "    claims = [\"according to the court\",\"it is established\",\"the law states\",\"precedent\"]\n",
    "    return 1.0 if any(w in text.lower() for w in claims) else 0.4\n",
    "\n",
    "def severity_score(text):\n",
    "    severe = [\"torture\",\"death\",\"imprisonment\",\"discrimination\",\"inhuman\",\"degrading\"]\n",
    "    moderate = [\"detention\",\"restriction\",\"delay\"]\n",
    "    t = text.lower()\n",
    "    if any(w in t for w in severe): return 1.0\n",
    "    if any(w in t for w in moderate): return 0.6\n",
    "    return 0.3\n",
    "\n",
    "def article_risk(text):\n",
    "    high = [\"article 2\",\"article 3\",\"article 5\",\"article 6\"]\n",
    "    medium = [\"article 8\",\"article 10\",\"article 14\"]\n",
    "    t = text.lower()\n",
    "    if any(w in t for w in high): return 1.0\n",
    "    if any(w in t for w in medium): return 0.7\n",
    "    return 0.4\n",
    "\n",
    "def impact_risk(text):\n",
    "    impact = [\"appeal\",\"file a case\",\"legal action\",\"court\",\"claim compensation\"]\n",
    "    return 1.0 if any(w in text.lower() for w in impact) else 0.4\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Apply v3 Features\n",
    "# --------------------------------------------------\n",
    "\n",
    "df[\"DomainRisk\"] = df[\"llm_answer\"].apply(domain_risk)\n",
    "df[\"ActionRisk\"] = df[\"llm_answer\"].apply(actionability)\n",
    "df[\"AuthorityRisk\"] = df[\"llm_answer\"].apply(authority_claim)\n",
    "df[\"SeverityRisk\"] = df[\"llm_answer\"].apply(severity_score)\n",
    "df[\"ArticleRisk\"] = df[\"llm_answer\"].apply(article_risk)\n",
    "df[\"ImpactRisk\"] = df[\"llm_answer\"].apply(impact_risk)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Feature Matrix\n",
    "# --------------------------------------------------\n",
    "\n",
    "X = df[[\n",
    "    \"FactRisk\",\"InterpretationRisk\",\"RetrievalMismatch\",\"ConfidenceGap\",\n",
    "    \"DomainRisk\",\"ActionRisk\",\"AuthorityRisk\",\n",
    "    \"SeverityRisk\",\"ArticleRisk\",\"ImpactRisk\"\n",
    "]]\n",
    "\n",
    "y = df[\"GovTarget\"]\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Train/Test Split\n",
    "# --------------------------------------------------\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "policy = LinearRegression()\n",
    "policy.fit(X_train, y_train)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Governance Decision\n",
    "# --------------------------------------------------\n",
    "\n",
    "def trustreg_v3(score, threshold=0.0):\n",
    "    return \"BLOCK\" if score>threshold else \"APPROVE\"\n",
    "\n",
    "df_test = df.loc[X_test.index].copy()\n",
    "\n",
    "df_test[\"GovScore_v3\"] = policy.predict(X_test)\n",
    "df_test[\"TrustReg_v3\"] = df_test[\"GovScore_v3\"].apply(trustreg_v3)\n",
    "df_test[\"TrustReg_v3_pred\"] = df_test[\"TrustReg_v3\"].apply(lambda d: 1 if d==\"APPROVE\" else 0)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Evaluation\n",
    "# --------------------------------------------------\n",
    "\n",
    "df_test[\"TrustReg_v3_harm\"] = df_test.apply(\n",
    "    lambda r: decision_harm(r[\"TrustReg_v3_pred\"], r[\"binary_violation\"]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df_test[\"TrustReg_v3_utility\"] = df_test.apply(\n",
    "    lambda r: decision_utility(r[\"TrustReg_v3_pred\"], r[\"binary_violation\"]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(\"TEST TrustReg v3 Harm:\", df_test[\"TrustReg_v3_harm\"].sum())\n",
    "print(\"TEST TrustReg v3 Utility:\", df_test[\"TrustReg_v3_utility\"].sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5dd5a5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../outputs/trustreg_v3_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e46c016d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST TrustReg RF Harm: 676\n",
      "TEST TrustReg RF Utility: 461\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=200, max_depth=6, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "df_test[\"GovScore_rf\"] = rf.predict(X_test)\n",
    "df_test[\"TrustReg_rf\"] = df_test[\"GovScore_rf\"].apply(trustreg_v3)\n",
    "\n",
    "print(\"TEST TrustReg RF Harm:\", df_test.apply(\n",
    "    lambda r: decision_harm(1 if r[\"TrustReg_rf\"]==\"APPROVE\" else 0, r[\"binary_violation\"]),\n",
    "    axis=1\n",
    ").sum())\n",
    "print(\"TEST TrustReg RF Utility:\", df_test.apply(\n",
    "    lambda r: decision_utility(1 if r[\"TrustReg_rf\"]==\"APPROVE\" else 0, r[\"binary_violation\"]),\n",
    "    axis=1\n",
    ").sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f67bc4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST TrustReg XGB Harm: 684\n",
      "TEST TrustReg XGB Utility: 533\n"
     ]
    }
   ],
   "source": [
    "# ...existing code...\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb = XGBRegressor(n_estimators=300, max_depth=5, learning_rate=0.05)\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "df_test[\"GovScore_xgb\"] = xgb.predict(X_test)\n",
    "df_test[\"TrustReg_xgb\"] = df_test[\"GovScore_xgb\"].apply(trustreg_v3)\n",
    "\n",
    "# ...existing code...\n",
    "df_test[\"TrustReg_xgb_harm\"] = df_test.apply(\n",
    "    lambda r: decision_harm(1 if r[\"TrustReg_xgb\"]==\"APPROVE\" else 0, r[\"binary_violation\"]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df_test[\"TrustReg_xgb_utility\"] = df_test.apply(\n",
    "    lambda r: decision_utility(1 if r[\"TrustReg_xgb\"]==\"APPROVE\" else 0, r[\"binary_violation\"]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(\"TEST TrustReg XGB Harm:\", df_test[\"TrustReg_xgb_harm\"].sum())\n",
    "print(\"TEST TrustReg XGB Utility:\", df_test[\"TrustReg_xgb_utility\"].sum())\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6912fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X_train, X_test, rf, xgb, trustreg_v3 already trained\n",
    "\n",
    "df_test = df.loc[X_test.index].copy()\n",
    "\n",
    "df_test[\"TrustReg_rf\"] = rf.predict(X_test)\n",
    "df_test[\"TrustReg_rf\"] = df_test[\"TrustReg_rf\"].apply(trustreg_v3)\n",
    "\n",
    "df_test[\"TrustReg_xgb\"] = xgb.predict(X_test)\n",
    "df_test[\"TrustReg_xgb\"] = df_test[\"TrustReg_xgb\"].apply(trustreg_v3)\n",
    "\n",
    "# Also keep LR\n",
    "df_test[\"TrustReg_v3\"] = df_test[\"GovScore\"].apply(trustreg_v3)\n",
    "\n",
    "# Save final comparison CSV\n",
    "df_test.to_csv(\"../outputs/trustreg_model_comparison.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
